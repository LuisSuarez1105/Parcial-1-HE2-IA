# -*- coding: utf-8 -*-
"""Parcial1AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h546p6GiEw80z6wFfZoO0-UCfHIdz50v
"""

# 0. Instalaciones necesarias
!pip install -q pandas numpy scikit-learn xgboost matplotlib seaborn datasets

# 1. Importaciones de librerías
import pandas as pd
import numpy as np
from datasets import load_dataset
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (confusion_matrix, roc_curve, roc_auc_score,
                          classification_report)

# Modelos que vamos a probar
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

# 2. Cargar el dataset de estudiantes
dataset = load_dataset("scikit-learn/student-alcohol-consumption")
df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(1044)))

print("Información del dataset cargado:")
print(f"Dimensiones: {df.shape}")
print(f"Columnas: {list(df.columns)}")
print(f"\nDistribución de la variable objetivo:")
print(df['G3'].value_counts(normalize=True))

# 3. Revisión rápida de valores únicos por columna
for col in df.columns:
   print(f"\nValue counts for column: {col}")
   print(df[col].value_counts())

# 3.1 Limpieza de duplicados
key_cols = [
    "school","sex","age","address","famsize","Pstatus",
    "Medu","Fedu","Mjob","Fjob","reason","nursery","internet"
]
df_clean = df.drop_duplicates(subset=key_cols, keep="first")
print("Filas originales:", len(df))
print("Filas después de limpiar:", len(df_clean))
print("Duplicados eliminados:", len(df) - len(df_clean))


# 4. Función de preprocesamiento (normaliza numéricas y codifica categóricas)
def preprocess_student_data(df):
    # Variables numéricas (se escalan con StandardScaler)
    numeric_features= [
        'age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures',
        'famrel', 'freetime', 'goout', 'Dalc', 'Walc',
        'health', 'absences', 'G1', 'G2'
    ]
    # Variables categóricas (se codifican con LabelEncoder)
    categorical_features = [
        'school', 'sex', 'address', 'famsize', 'Pstatus',
        'Mjob', 'Fjob', 'reason', 'guardian',
        'schoolsup', 'famsup', 'paid', 'activities',
        'nursery', 'higher', 'internet', 'romantic'
    ]

    # Escalado de variables numéricas
    scaler = StandardScaler()
    df[numeric_features] = scaler.fit_transform(df[numeric_features])

    # Codificación de variables categóricas
    for feature in categorical_features:
        le = LabelEncoder()
        df[feature] = le.fit_transform(df[feature].astype(str))

    # Definir X (features) y y (target binario: aprobado >=10)
    X = df.drop(columns=['G3'])
    y = (df['G3'] >= 10).astype(int)

    return X, y, scaler

# 5. Aplicamos preprocesamiento
X, y, scaler = preprocess_student_data(df)

print("\nDatos después del preprocesamiento:")
print(f"Forma de X: {X.shape}")
print(f"Primeras 3 columnas de X:\n{X.iloc[:5, :3]}")
print(f"\nDistribución de y: {y.value_counts()}")

# 6. División en entrenamiento y prueba (80% - 20%)
X_train, X_test, y_train, y_test = train_test_split(
   X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTamaño conjunto entrenamiento: {X_train.shape}")
print(f"Tamaño conjunto prueba: {X_test.shape}")
print(f"Distribución de clases en entrenamiento: {pd.Series(y_train).value_counts(normalize=True).round(3).to_dict()}")


# 7. Definir modelos base
models = {
   'KNN': KNeighborsClassifier(),
   'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),
   'XGBoost': xgb.XGBClassifier(
       random_state=42,
       use_label_encoder=False,
       eval_metric="logloss"
   )
}

# 7.1 Definir grids de hiperparámetros para cada modelo
param_grids = {
    'KNN': {
        'n_neighbors': [3, 5, 7, 9],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean']
    },
    'RandomForest': {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_leaf': [1, 5, 10],
        'max_features': ['sqrt']
    },
    'XGBoost': {
        'learning_rate': [0.01, 0.1, 0.2],
        'n_estimators': [100, 200],
        'max_depth': [3, 6, 10],
        'subsample': [0.8, 1.0],
        'colsample_bytree': [0.8, 1.0]
    }
}

# 7.2 Ajuste de hiperparámetros con GridSearchCV
best_models = {}
for name, model in models.items():
    print(f"\n Buscando mejores hiperparámetros para {name}...")
    grid = GridSearchCV(
        model,
        param_grids[name],
        cv=3,            # 3-fold CV interno (puedes subirlo a 5 si quieres más robustez)
        scoring='f1',    # optimizamos F1-score
        n_jobs=-1,
        verbose=1
    )
    grid.fit(X_train, y_train)
    best_models[name] = grid.best_estimator_
    print(f" {name} mejores parámetros: {grid.best_params_}")
    print(f" {name} mejor F1 (CV): {grid.best_score_:.3f}")

# 8. Entrenamiento de modelos y predicciones
predictions = {}
probabilities = {}

for name, model in models.items():
    print(f"Entrenando {name}...")
    model.fit(X_train, y_train)                # Entrenar
    predictions[name] = model.predict(X_test)  # Predicciones
    probabilities[name] = model.predict_proba(X_test)[:, 1]  # Probabilidades


# 9. Matriz de confusión
def plot_confusion_matrices(y_true, predictions_dict):
    fig, axes = plt.subplots(1, len(predictions_dict), figsize=(15, 5))
    axes = axes.ravel()

    for idx, (name, y_pred) in enumerate(predictions_dict.items()):
        cm = confusion_matrix(y_true, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', ax=axes[idx], cmap='Blues')
        axes[idx].set_title(f'{name}')
        axes[idx].set_xlabel('Predicción')
        axes[idx].set_ylabel('Real')

    plt.tight_layout()
    plt.show()

plot_confusion_matrices(y_test, predictions)

# 10. Curvas ROC para comparar modelos
def plot_roc_curves(y_true, probabilities_dict):
    plt.figure(figsize=(8, 6))

    for name, probs in probabilities_dict.items():
        fpr, tpr, _ = roc_curve(y_true, probs)
        auc = roc_auc_score(y_true, probs)
        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')

    plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio')
    plt.xlabel('Tasa de Falsos Positivos')
    plt.ylabel('Tasa de Verdaderos Positivos')
    plt.title('Curvas ROC')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

plot_roc_curves(y_test, probabilities)

# 11. Métricas de evaluación en test (Accuracy, Precision, Recall, F1, AUC)
print("\nMétricas de evaluación en test:")
print("-" * 70)
print(f"{'Modelo':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'AUC':<10}")
print("-" * 70)

for name in predictions.keys():
    report = classification_report(y_test, predictions[name], output_dict=True)
    auc = roc_auc_score(y_test, probabilities[name])

    print(f"{name:<15} "
          f"{report['accuracy']:<10.3f} "
          f"{report['1']['precision']:<10.3f} "
          f"{report['1']['recall']:<10.3f} "
          f"{report['1']['f1-score']:<10.3f} "
          f"{auc:<10.3f}")


# 12. Validación cruzada (5 folds, usando F1-score)
print("\nValidación cruzada (F1-score por modelo):")
print("-" * 60)

skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

cv_scores = {}
for name, model in models.items():
    scores = cross_val_score(model, X_train, y_train, cv=skfold, scoring='f1')
    cv_scores[name] = scores
    print(f"{name:<15} {np.mean(scores):.3f} ± {np.std(scores):.3f}")

# 12.1 Visualización de la validación cruzada
plt.figure(figsize=(8, 6))
plt.boxplot([cv_scores[name] for name in models.keys()],
            labels=models.keys())
plt.title("Validación Cruzada Estratificada (F1-Score)")
plt.ylabel("F1-Score")
plt.grid(True, alpha=0.3)
plt.show()

# === 13. Guardar base procesada ===

df_processed = X.copy()
df_processed["target"] = y

df_processed.to_csv("student_data_processed.csv", index=False)

print("Base procesada guardada en 'student_data_processed.csv'")